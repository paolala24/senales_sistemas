{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolala24/senales_sistemas/blob/main/Talleres/Copy_of_youtube_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmaPHWwtvLHa"
      },
      "outputs": [],
      "source": [
        "#cargar datos desde drive acceso libre\n",
        "\n",
        "FILEID = \"18CxyyZVe134vyYN6FRmS2uyNFqzaYabS\"\n",
        "#\"1HZ3-I9dSYyrV3JGDd-E1BPV_JVzVzV-j\"\n",
        "\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O  canciones.xlsx && rm -rf /tmp/cookies.txt\n",
        "#!unzip -o codigos.zip\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_ = 'canciones.xlsx'#leer archivo xlsx con link, band, type\n",
        "X  = pd.read_excel(file_)\n",
        "X#imprimir filas iniciales"
      ],
      "metadata": {
        "id": "NF9zfZdPv7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar librerias necesarias para descargar audios youtube\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile\n",
        "\n",
        "import os\n",
        "import yt_dlp as youtube_dl\n",
        "\n",
        "#funcion para descargar mp3 desde youtube\n",
        "def download_ytvid_as_mp3(video_url,name):\n",
        "    #video_url = input(\"enter url of youtube video:\")\n",
        "    video_info = youtube_dl.YoutubeDL().extract_info(url = video_url,download=False)\n",
        "    filename = f\"{name}.mp3\"\n",
        "    options={\n",
        "        'format':'bestaudio/best',\n",
        "        'keepvideo':False,\n",
        "        'outtmpl':filename,\n",
        "    }\n",
        "\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        ydl.download([video_info['webpage_url']])\n",
        "\n",
        "    print(\"Download complete... {}\".format(filename))"
      ],
      "metadata": {
        "id": "-0GnJhn9wYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "#crear carpeta con resultados\n",
        "try:\n",
        "  os.mkdir('results')\n",
        "except:\n",
        "  print(\"Carpeta results ya existe\")\n",
        "\n",
        "#recorrer excel con videos\n",
        "N, P = X.shape\n",
        "Ns = N * 5 #cantidad de segmentos por cancion\n",
        "\n",
        "for n in range(N):\n",
        "    print(f\"video {n+1} de {N}\")\n",
        "    print(f\"link: {X.loc[n,'link']}\\n\")\n",
        "    print(f\"band: {X.loc[n,'band']}\\n\")\n",
        "    print(f\"type: {X.loc[n,'type']}\\n\")\n",
        "    #ruta video n-th\n",
        "    name_ = 'results/'+X.loc[n,'band']+\"_\"+str(n)+\"_\"+str(X.loc[n,'type_num']) # #video+nombre+tipo de genero musical\n",
        "    #descargar mp3 desde youtube\n",
        "    download_ytvid_as_mp3(X.loc[n,'link'],name_)\n",
        "    #convertir a .wav\n",
        "    subprocess.call(['ffmpeg','-y', '-i', name_+'.mp3',\n",
        "                   name_+'.wav'])"
      ],
      "metadata": {
        "id": "8q0Xv9BcwzeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar .wavs y partir audios\n",
        "#lista archivos .wav\n",
        "path = 'results/'\n",
        "wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "wav_files"
      ],
      "metadata": {
        "id": "gX5bdp-7w--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile #instalar sondfile"
      ],
      "metadata": {
        "id": "rYfmNwVVzpF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf # para instalar pip install soundfile\n",
        "from scipy.signal import resample_poly\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#leer archivos y crear np.array audios\n",
        "fs = 48000\n",
        "tl = np.array([30,40,50,60,70,80]) #puntos lectura\n",
        "ts = 5 #t segmento\n",
        "# The total number of samples for each segment at the target fs\n",
        "segment_length_fs = int(ts * fs)\n",
        "Ns = len(wav_files)*len(tl) #cantidad segmentos\n",
        "# x_t should be initialized with the shape corresponding to the target fs\n",
        "x_t = np.zeros((Ns, segment_length_fs, 2)) #Ns segmentos, cantidad de muestras, 2 canales (stereo)\n",
        "label = np.zeros((Ns,1)) #vector tipo de genero\n",
        "type_c = X['type'].unique()\n",
        "name_c = []\n",
        "#leer archivos wav\n",
        "i = 0\n",
        "for name in wav_files:#lectura audio .wav\n",
        "    x, fs_i = sf.read(path+name)\n",
        "    # Ensure x is at least 2D (for stereo)\n",
        "\n",
        "    if x.ndim == 1:\n",
        "        x = np.expand_dims(x, axis=1) # Add a channel dimension if mono\n",
        "    if x.shape[1] == 1: # If still mono after expand_dims\n",
        "        x = np.repeat(x, 2, axis=1) # Convert mono to stereo by repeating the channel\n",
        "\n",
        "    # Check if the audio file has enough data for the requested segments\n",
        "    if len(x) < int(fs_i * (tl[-1] + ts)):\n",
        "        print(f\"Warning: File {name} is too short for all requested segments. Skipping some segments.\")\n",
        "        valid_tl = tl[tl + ts <= len(x)/fs_i]\n",
        "    else:\n",
        "        valid_tl = tl\n",
        "\n",
        "    for ti in valid_tl: #segmentos de tiempo\n",
        "        print(name,'x',x.shape,'fs actual:',fs_i)\n",
        "\n",
        "        # Slice based on the original sampling rate fs_i\n",
        "        start_sample = int(fs_i * ti)\n",
        "        end_sample = int(fs_i * (ti + ts))\n",
        "        xc = x[start_sample:end_sample, :]\n",
        "\n",
        "        # Check if the sliced segment has enough data for resampling\n",
        "        # This can happen if the calculated end_sample exceeds the actual audio length\n",
        "        if xc.shape[0] < int(ts * fs_i):\n",
        "            print(f\"Warning: Segment from {ti}s to {ti+ts}s in {name} is shorter than expected. Skipping.\")\n",
        "            continue # Skip this segment\n",
        "\n",
        "        if fs_i != fs:\n",
        "            # Resample using resample_poly\n",
        "            # The output length of resample_poly is len(xc) * up / down\n",
        "            # We want the resampled length to be exactly segment_length_fs\n",
        "            # So we need to calculate up and down such that len(xc) * up / down = segment_length_fs\n",
        "            # Or simply use the desired number of samples directly if supported by resample_poly\n",
        "            # resample_poly can take 'nyq' or 'kaiser_beta' arguments for filter design,\n",
        "            # but for simple resampling to a target number of points, a direct approach is needed.\n",
        "            # A simpler resample function might be better, or calculate up/down differently.\n",
        "\n",
        "            # Let's use a method that targets the desired number of samples directly.\n",
        "            # scipy.signal.resample can do this, but it uses FFT and might not be ideal.\n",
        "            # Let's adjust the resampling calculation with resample_poly to ensure the correct output size.\n",
        "            # Target output size is segment_length_fs.\n",
        "            # Current size is xc.shape[0].\n",
        "            # We want xc.shape[0] * (up / down) = segment_length_fs\n",
        "            # Let's find up and down that approximate fs/fs_i\n",
        "            # A more robust way is to use a library that handles resampling to a specific length.\n",
        "            # For now, let's ensure the resampled array is truncated or padded if necessary,\n",
        "            # although it's better to get the resampling right.\n",
        "\n",
        "            # A common approach for arbitrary resampling is\n",
        "            # import librosa\n",
        "            # xc_resampled = librosa.resample(xc, orig_sr=fs_i, target_sr=fs)\n",
        "            # However, this outputs a 1D array for mono. Need to handle stereo.\n",
        "\n",
        "            # Let's stick with resample_poly but ensure the output is the correct size.\n",
        "            # If resampling makes it slightly longer or shorter, we'll handle it.\n",
        "            gcd_val = np.gcd(fs, fs_i)\n",
        "            up_val = fs // gcd_val\n",
        "            down_val = fs_i // gcd_val\n",
        "\n",
        "            # Resample each channel separately\n",
        "            xc_resampled_ch1 = resample_poly(xc[:, 0], up=up_val, down=down_val)\n",
        "            xc_resampled_ch2 = resample_poly(xc[:, 1], up=up_val, down=down_val)\n",
        "\n",
        "            # Combine channels\n",
        "            xc_resampled = np.stack((xc_resampled_ch1, xc_resampled_ch2), axis=-1)\n",
        "\n",
        "            # Ensure the resampled segment has the target length (segment_length_fs)\n",
        "            if xc_resampled.shape[0] > segment_length_fs:\n",
        "                xc_resampled = xc_resampled[:segment_length_fs, :]\n",
        "            elif xc_resampled.shape[0] < segment_length_fs:\n",
        "                # Pad with zeros if shorter\n",
        "                padding = np.zeros((segment_length_fs - xc_resampled.shape[0], 2))\n",
        "                xc_resampled = np.vstack((xc_resampled, padding))\n",
        "\n",
        "            xc = xc_resampled # Use the resampled array\n",
        "            print(f\"Resampled to shape: {xc.shape}\")\n",
        "\n",
        "        # Now xc should have the shape (segment_length_fs, 2) which is (240000, 2)\n",
        "        if xc.shape[0] != segment_length_fs:\n",
        "             print(f\"Error: Resampled segment has incorrect length {xc.shape[0]}. Expected {segment_length_fs}. Skipping.\")\n",
        "             continue # Skip this segment if resampling failed to produce correct length\n",
        "\n",
        "\n",
        "        x_t[i] = xc\n",
        "        # The label indexing seems to assume the order of wav_files matches the order in X\n",
        "        # and the type_num is the last digit before '.wav' and is 1 or 2.\n",
        "        # This might be fragile. Consider using the 'type_num' column from X directly\n",
        "        # based on the filename or a mapping.\n",
        "        # For now, sticking to the original logic for the label.\n",
        "        try:\n",
        "             # Extract type_num from the filename\n",
        "             parts = name.split('_')\n",
        "             type_num_str = parts[-1].split('.')[0]\n",
        "             label[i] = int(type_num_str)\n",
        "        except (IndexError, ValueError):\n",
        "             print(f\"Warning: Could not extract type_num from filename {name}. Setting label to 0.\")\n",
        "             label[i] = 0 # Assign a default or error label\n",
        "\n",
        "        # The name_c logic also seems to assume the filename format.\n",
        "        # Sticking to original logic.\n",
        "        name_c += [name[:-4]] # Remove '.wav' from the end\n",
        "\n",
        "\n",
        "        print(f\"{i} lectura: {name}; segundo {ti}:{ti+ts}; tipo música: {type_c[int(label[i])-1]}\")\n",
        "        i+=1\n",
        "\n",
        "# After the loop, if some segments were skipped, the actual number of populated segments in x_t and label\n",
        "# might be less than Ns. We should truncate these arrays to the actual number of populated segments.\n",
        "# Ns was calculated based on the initial assumption of processing all segments.\n",
        "# Let's re-calculate the effective Ns (number of processed segments).\n",
        "effective_Ns = i\n",
        "x_t = x_t[:effective_Ns]\n",
        "label = label[:effective_Ns]\n",
        "name_c = name_c[:effective_Ns]\n",
        "\n",
        "x_t.shape"
      ],
      "metadata": {
        "id": "nOn4GrOkzZvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio #reproducir segmento\n",
        "i = 10\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "YM3ltcs6zOHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculo de fourier\n",
        "vf = np.fft.rfftfreq(x_t.shape[1],1/fs) #calculo vector de frecuencias\n",
        "Xw = np.fft.rfft(x_t,axis=1).mean(axis=-1) #transformada rapida de Fourier para señal Real a lo largo del tiempo (axis=1) y se promedian los dos canales\n",
        "Xw.shape"
      ],
      "metadata": {
        "id": "qcd1pUoz2KM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grafica tiempo y fourier\n",
        "plt.plot(np.arange(0,ts,1/fs),x_t.mean(axis=-1).T) #se promedian los dos canales stereo\n",
        "plt.xlabel('t[s]')\n",
        "plt.ylabel('x(t)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NiacFvIx4vpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(vf,abs(Xw).T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roZkalWc5cqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se normalizan espectros entre 0 y 1 para evitar inconsistencias por ampliltudes máximas\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sca = MinMaxScaler()\n",
        "Xw_ = sca.fit_transform(abs(Xw).T).T\n",
        "\n",
        "plt.plot(vf,Xw_.T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()\n",
        "\n",
        "#en dB\n",
        "plt.plot(vf,(20*np.log10(Xw_+1e-10)).T) # se suma 1e-10 para evitar discontinuidad del log\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)| dB')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DR4Tw83c6b-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota**: Generalmente el espectro se presenta en [decibeles [dB]](https://es.wikipedia.org/wiki/Decibelio)"
      ],
      "metadata": {
        "id": "AXaYxHDVQj1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "#visualización de datos\n",
        "red_ = TSNE(perplexity = 20,n_components=2,random_state=123,learning_rate='auto',init='pca')\n",
        "#red_ = PCA(n_components=2,random_state=123)\n",
        "fmax = 7000\n",
        "X_2D = red_.fit_transform(Xw_[:,:fmax]) #se tiene en cuenta el espectro hasta fmax Hz"
      ],
      "metadata": {
        "id": "UZGVCWRk1eAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar separabilidad 2D\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "color_ = [\"b\",\"y\"]\n",
        "#nombre cancion\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label,s=1)\n",
        "for i, tex in enumerate(name_c):\n",
        "    #print(f\"{i} {tex}\")\n",
        "    plt.text(X_2D[i,0]*1.025,X_2D[i,1]*1.025, tex[:-2]+\"_\"+str(i), fontsize=6,color=color_[int(label[i]-1)])\n",
        "\n",
        "#plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A2Tmfe-57ZEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproducir audio\n",
        "i = 5\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "fubfCcH5CHzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 14\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "z9NRefvJD7Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "#guardar modelo\n",
        "os.mkdir('modelo')\n",
        "filename_ = 'modelo/rap_vs_pop'\n",
        "model_ ={'Xw_':Xw_,'fmax': fmax, 'label' : label, 'name_c' : name_c, 'vf':vf,'fs':fs}\n",
        "joblib.dump(model_,filename_+\".pkl\")\n"
      ],
      "metadata": {
        "id": "JFDhqdxH79cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descargar modelo\n",
        "#guardar resultados\n",
        "from google.colab import files\n",
        "from datetime import date, datetime\n",
        "import shutil\n",
        "#guardar resultados\n",
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'modelo'\n",
        "shutil.make_archive(namefile, 'zip', 'modelo')\n",
        "files.download(namefile+'.zip')\n",
        "\n",
        "#el archivo .zip puede cargarse en drive y utilizarse en otro cuaderno para detectar género musical de nuevos segmentos"
      ],
      "metadata": {
        "id": "7zWJ8LNQBjNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar modelo\n",
        "my_model_loaded = joblib.load(filename_+\".pkl\")\n",
        "my_model_loaded.keys()"
      ],
      "metadata": {
        "id": "LRJ7txqCA1bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 1. DESCARGA DE CANCIONES DESDE EL EXCEL\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# Instalamos gdown si no está disponible (solo si estás en Colab o entorno nuevo)\n",
        "try:\n",
        "    import gdown\n",
        "except ImportError:\n",
        "    import os\n",
        "    os.system('pip install gdown')\n",
        "    import gdown\n",
        "\n",
        "# Identificador de tu Google Sheet con las 30 canciones\n",
        "FILEID = \"1HZ3-I9dSYyrV3JGDd-E1BPV_JVzVzV-j\"\n",
        "\n",
        "# Descargamos el Excel desde Google Drive con gdown\n",
        "gdown.download(f\"https://drive.google.com/uc?id={FILEID}\", \"canciones.xlsx\", quiet=False)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "import yt_dlp as youtube_dl\n",
        "import soundfile as sf\n",
        "\n",
        "# Leemos el Excel que contiene: link, band, type, type_num\n",
        "X = pd.read_excel(\"canciones.xlsx\")\n",
        "\n",
        "# Creamos la carpeta donde guardaremos mp3 y wav\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Función para descargar un video de YouTube como MP3\n",
        "def download_ytvid_as_mp3(video_url, name):\n",
        "    video_info = youtube_dl.YoutubeDL().extract_info(url=video_url, download=False)\n",
        "    filename = f\"{name}.mp3\"\n",
        "    options = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'keepvideo': False,\n",
        "        'outtmpl': filename,\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        ydl.download([video_info['webpage_url']])\n",
        "    print(f\"Download complete: {filename}\")\n",
        "\n",
        "# Iteramos sobre las filas del Excel, descargamos y convertimos a WAV\n",
        "N = len(X)\n",
        "for n in range(N):\n",
        "    link  = X.loc[n, 'link']\n",
        "    band  = X.loc[n, 'band']\n",
        "    tnum  = X.loc[n, 'type_num']\n",
        "    name_ = f\"results/{band}_{n}_{tnum}\"\n",
        "    print(f\"\\n=== Descargando canción {n+1}/{N} ===\")\n",
        "    print(f\"Link: {link}\")\n",
        "    download_ytvid_as_mp3(link, name_)\n",
        "    # Convertimos el MP3 a WAV (48 kHz, estéreo si aplica)\n",
        "    subprocess.call([\n",
        "        'ffmpeg', '-y',\n",
        "        '-i', f\"{name_}.mp3\",\n",
        "        '-ar', '48000',   # sample rate 48 kHz\n",
        "        '-ac', '2',       # 2 canales estéreo\n",
        "        f\"{name_}.wav\"\n",
        "    ])\n",
        "    # Borramos el mp3 original para ahorrar espacio\n",
        "    os.remove(f\"{name_}.mp3\")\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 2. PARTICIONAR CADA WAV EN 5 FRAGMENTOS DE 5 SEGUNDOS → 50 MUESTRAS TOTALES\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# Listamos todos los archivos .wav que acabamos de generar\n",
        "path = 'results/'\n",
        "wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "print(f\"\\nTotal de archivos WAV encontrados: {len(wav_files)} (deberían ser 10)\")\n",
        "\n",
        "# Parámetros de segmentación\n",
        "fs = 48000            # frecuencia de muestreo (48 kHz)\n",
        "ts = 5                # duración de cada segmento en segundos\n",
        "# Para obtener 50 segmentos en total a partir de 10 canciones,\n",
        "# necesitamos 5 offsets (5 segundos de duración) por cada canción:\n",
        "tl = [10,  40,  70, 100, 130]   # instantes (en segundos) donde empieza cada fragmento de 5 s\n",
        "\n",
        "Ns = len(wav_files) * len(tl)   # 10 canciones × 5 offsets = 50 segmentos\n",
        "# Preasignamos arrays:\n",
        "x_t    = np.zeros((Ns, int(ts*fs), 2), dtype=np.float32)  # Ns segmentos, muestras (5s×48kHz), 2 canales\n",
        "label  = np.zeros((Ns, 1),  dtype=int)                    # etiqueta de género (1 o 2)\n",
        "name_c = []                                               # nombre de canción (sin sufijo \"_n_type\")\n",
        "\n",
        "i = 0\n",
        "for name in wav_files:\n",
        "    filepath = os.path.join(path, name)\n",
        "    x, fs_file = sf.read(filepath)    # x.shape = (total_muestras, 2)\n",
        "    if fs_file != fs:\n",
        "        raise RuntimeError(f\"Esperamos 48 kHz, pero {name} está a {fs_file} Hz\")\n",
        "    # Etiqueta de género tomada del penúltimo carácter antes de \".wav\": \"..._{type}.wav\"\n",
        "    genre_num = int(name[-5])  # asumiendo formato \"..._{type}.wav\"\n",
        "    base_name = name[:-6]      # para evitar \"..._n_t.wav\"\n",
        "    for ti_seg in tl:\n",
        "        start = int(ti_seg * fs)\n",
        "        end   = int((ti_seg + ts) * fs)\n",
        "        x_t[i]   = x[start:end, :]      # recortamos 5 segundos (estéreo)\n",
        "        label[i] = genre_num\n",
        "        name_c.append(base_name)\n",
        "        print(f\"{i:02d} → {name}   segundos {ti_seg}:{ti_seg+ts}   género {genre_num}\")\n",
        "        i += 1\n",
        "\n",
        "print(f\"\\nForma de x_t: {x_t.shape}   → 50 segmentos de 5 s en estéreo\")\n",
        "print(f\"Forma de label: {label.shape}\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 3. CÁLCULO DE LA FFT Y NORMALIZACIÓN DE CADA SEGMENTO\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# 3.A. Construimos el vector de frecuencias completo para rfft (para ts×fs muestras)\n",
        "vf = np.fft.rfftfreq(int(ts*fs), 1/fs)\n",
        "\n",
        "# 3.B. Calculamos la FFT real para cada segmento (axis=1 recorre el tiempo)\n",
        "#      Luego promediamos ambos canales en el dominio de magnitudes.\n",
        "Xw = np.fft.rfft(x_t, axis=1)          # shape = (50, N_bins, 2)\n",
        "Xw_mag = np.mean(np.abs(Xw), axis=2)   # shape = (50, N_bins)\n",
        "\n",
        "# 3.C. Escogemos un fmax razonable (p. ej. 7000 Hz) para recortar el espectro\n",
        "fmax = 7000\n",
        "fmax_idx = np.argmin(np.abs(vf - fmax))  # índice del bin más cercano a fmax\n",
        "print(f\"\\nBin máximo seleccionado (f <= {fmax} Hz):  {fmax_idx}  (f = {vf[fmax_idx]:.1f} Hz)\")\n",
        "\n",
        "# 3.D. Cortamos el espectro a [0 : fmax_idx]\n",
        "Xw_crop = Xw_mag[:, :fmax_idx]\n",
        "\n",
        "# 3.E. Normalizamos entre 0 y 1 cada vector de frecuencias\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sca = MinMaxScaler()\n",
        "Xw_norm = sca.fit_transform(Xw_crop)   # shape = (50, fmax_idx)\n",
        "\n",
        "print(f\"Dataset final de espectros normalizados:  {Xw_norm.shape}   (50 muestras × {fmax_idx} bins)\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 4. VISUALIZACIÓN RÁPIDA Y SEPARABILIDAD 2D\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 4.A. Graficar magnitud del primer segmento (solo para verificar)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(vf[:fmax_idx], Xw_norm[0], color='tab:blue')\n",
        "plt.title(\"Espectro normalizado (fragmento #0)\")\n",
        "plt.xlabel(\"Frecuencia [Hz]\")\n",
        "plt.ylabel(\"Magnitud normalizada\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 4.B. Separabilidad 2D usando TSNE\n",
        "red_ = TSNE(perplexity=20, n_components=2, random_state=123, learning_rate='auto', init='pca')\n",
        "X_2D = red_.fit_transform(Xw_norm)  # shape = (50, 2)\n",
        "\n",
        "# Graficar scatter con colorbar\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.scatter(X_2D[:,0], X_2D[:,1], c=label.ravel(), cmap='viridis', s=20)\n",
        "plt.colorbar(label=\"Género (1 vs 2)\")\n",
        "plt.title(\"Separabilidad 2D (TSNE) de los 50 segmentos\")\n",
        "plt.xlabel(\"Dim 1\")\n",
        "plt.ylabel(\"Dim 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Graficar scatter con nombres de canciones\n",
        "color_ = [\"b\", \"y\"]\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.scatter(X_2D[:,0], X_2D[:,1], c=label.ravel(), s=10, cmap='viridis')\n",
        "for idx, tex in enumerate(name_c):\n",
        "    plt.text(\n",
        "        X_2D[idx,0] * 1.025,\n",
        "        X_2D[idx,1] * 1.025,\n",
        "        tex.split('/')[-1],\n",
        "        fontsize=6,\n",
        "        color=color_[int(label[idx,0] - 1)]\n",
        "    )\n",
        "plt.title(\"Mapa 2D con etiquetas de canciones\")\n",
        "plt.xlabel(\"Dim 1\")\n",
        "plt.ylabel(\"Dim 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 5. ENTRENAMIENTO DEL CLASIFICADOR KNN (DISTANCIA EUCLÍDEA)\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "knn.fit(Xw_norm, label.ravel())\n",
        "\n",
        "os.makedirs('modelo', exist_ok=True)\n",
        "joblib.dump({\n",
        "    'knn_model': knn,\n",
        "    'scaler'   : sca,\n",
        "    'fmax_idx' : fmax_idx,\n",
        "    'vf'       : vf[:fmax_idx],\n",
        "    'fs'       : fs\n",
        "}, 'modelo/knn_genre_detector.pkl')\n",
        "\n",
        "print(\"\\n—> Entrenamiento completado: 50 vectores (5 s cada uno) con KNN guardado en modelo/knn_genre_detector.pkl\\n\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 6. CREAR UN FRAGMENTO DE PRUEBA EXTRAÍDO DE LOS 50 SEGMENTOS Y GUARDARLO COMO WAV\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "i_test = 32\n",
        "test_fragment = x_t[i_test]   # forma (240000, 2)\n",
        "sf.write(\"nuevo_fragmento_5s.wav\", test_fragment, fs)\n",
        "print(f\"→ Se creó 'nuevo_fragmento_5s.wav' a partir del segmento #{i_test} (género real = {int(label[i_test,0])})\\n\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 7. FUNCIÓN PARA DETECTAR GÉNERO DE UN NUEVO FRAGMENTO DE 5 s\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "def predict_genre_from_wav(new_wav_path: str, model_path: str = 'modelo/knn_genre_detector.pkl'):\n",
        "    \"\"\"\n",
        "    Carga un archivo WAV de exactamente 5 segundos (mono o estéreo),\n",
        "    calcula su FFT, recorta hasta fmax_idx, normaliza con el mismo MinMaxScaler\n",
        "    y predice el género usando el KNN entrenado.\n",
        "    Devuelve la etiqueta (1 o 2).\n",
        "    \"\"\"\n",
        "    mdl = joblib.load(model_path)\n",
        "    knn_loaded = mdl['knn_model']\n",
        "    sca_loaded = mdl['scaler']\n",
        "    fmax_idx  = mdl['fmax_idx']\n",
        "    fs_ref    = mdl['fs']\n",
        "\n",
        "    x5, fs_file = sf.read(new_wav_path)\n",
        "    if fs_file != fs_ref:\n",
        "        raise ValueError(f\"El WAV está a {fs_file} Hz; debe estar a {fs_ref} Hz.\")\n",
        "    n5 = 5 * fs_ref\n",
        "    if x5.ndim == 1:\n",
        "        if x5.shape[0] < n5:\n",
        "            raise ValueError(\"El archivo WAV es más corto de 5 segundos.\")\n",
        "        x5_seg = x5[:n5]\n",
        "    else:\n",
        "        if x5.shape[0] < n5:\n",
        "            raise ValueError(\"El WAV (estéreo) es más corto de 5 segundos.\")\n",
        "        x5_seg = x5[:n5, :]\n",
        "\n",
        "    if x5_seg.ndim == 1:\n",
        "        Xw5 = np.abs(np.fft.rfft(x5_seg))\n",
        "    else:\n",
        "        Xw5_0 = np.abs(np.fft.rfft(x5_seg[:, 0]))\n",
        "        Xw5_1 = np.abs(np.fft.rfft(x5_seg[:, 1]))\n",
        "        Xw5   = (Xw5_0 + Xw5_1) / 2.0\n",
        "\n",
        "    mag5_crop = Xw5[:fmax_idx].reshape(1, -1)\n",
        "    mag5_norm = sca_loaded.transform(mag5_crop)\n",
        "\n",
        "    pred = knn_loaded.predict(mag5_norm)[0]\n",
        "    return int(pred)\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 8. EJEMPLO DE USO DEL DETECTOR (SE PREDICE SOBRE 'nuevo_fragmento_5s.wav')\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "nuevo_fragmento = \"nuevo_fragmento_5s.wav\"  # creado en el paso anterior\n",
        "\n",
        "try:\n",
        "    genero_predicho = predict_genre_from_wav(nuevo_fragmento)\n",
        "    print(f\"\\n¡Género predicho para '{nuevo_fragmento}': {genero_predicho}  (1=Pop, 2=Vallenato)!\\n\")\n",
        "    display(Audio(nuevo_fragmento, rate=fs))\n",
        "except Exception as e:\n",
        "    print(\"Error al predecir género:\", e)"
      ],
      "metadata": {
        "id": "irVPbGdwBIkE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}